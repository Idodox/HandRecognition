{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image comparison\n",
    "- Size\n",
    "- Channels (RGB / grayscale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "from itertools import cycle\n",
    "from time import time\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leohe\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras import Input, Model\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.python.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resampling(src, r=2):\n",
    "    \"\"\"\n",
    "    Resamples an image n times using the pyrDown function from opencv\n",
    "    :param src: np.array - image\n",
    "    :param n: scalar - times\n",
    "    :return src: np.array - processed image\n",
    "    \"\"\"\n",
    "    for _ in range(r):\n",
    "        src = cv2.pyrDown(src)\n",
    "    return src\n",
    "\n",
    "def load_folders(filedir, n=2, resample=False, r=1/2, color=False):\n",
    "    \"\"\"\n",
    "    Loads the data from n folders, with(out) resampling\n",
    "    :param filedir: str - folder with all images\n",
    "    :param n: scalar - number of folder\n",
    "    :param resample: bool - flag for resampling\n",
    "    :param r: scalar - number of resamples\n",
    "    :param color: bool - read color images\n",
    "    :return stacked: data - images\n",
    "    :return label: data - label\n",
    "    \"\"\"\n",
    "    folder_list = [folder for folder in os.listdir(filedir)]\n",
    "    if color:\n",
    "        stacked  = np.empty((n * 3000, int(200 / (2 * r)), int(200 / (2 * r)), 3), dtype='uint8')\n",
    "        color_str = \"on BGR\"\n",
    "    else:\n",
    "        stacked  = np.empty((n * 3000, int(200 / (2 * r)), int(200 / (2 * r))), dtype='uint8')\n",
    "        color_str = \"on Grayscale\"\n",
    "    label = np.empty((n * 3000, 1), \n",
    "                     dtype='uint8')\n",
    "    count = 0\n",
    "    start = time()\n",
    "    for folder in folder_list[:n]:\n",
    "        subfolder = FILEDIR + '\\\\' + folder\n",
    "        file_list = [file for file in os.listdir(subfolder)]\n",
    "        print(\"Startting folder {} at {}\".format(folder, datetime.now()))\n",
    "        for file in file_list:\n",
    "            if color:\n",
    "                img = cv2.imread(subfolder + '\\\\' + file)\n",
    "            else:\n",
    "                img = cv2.imread(subfolder + '\\\\' + file, 0)\n",
    "            resample_str = \"without resamples\"\n",
    "            if resample and r >= 1:\n",
    "                resample_str = \"with {} resamples\".format(r)\n",
    "                img = resampling(img, int(r))\n",
    "            stacked[count] = img.astype('int8')\n",
    "            label[count] = LABEL[folder]\n",
    "            count += 1\n",
    "    print(u\"There were {} files, collected from {} folders, {}, {}.\\nExecution Time: \\u2248 {:.2f} [min]\"\n",
    "          .format(count, n, color_str, resample_str, (time() - start) / 60))\n",
    "    return stacked, label\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, normalize=False, cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    classes = np.arange(0, cm.shape[0])\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        title = 'Normalized confusion matrix'\n",
    "    else:\n",
    "        title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    np.set_printoptions(precision=2)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9,\n",
    "         'K':10, 'L':11, 'M':12, 'N':13, 'O':14, 'P':15, 'Q':16, 'R':17, 'S':18, 'T':19,\n",
    "         'U':20, 'V':21, 'W':22, 'X':23, 'Y':24, 'Z':25, \n",
    "         'del':26, 'nothing':27, 'space':28}\n",
    "\n",
    "FILEDIR = r'C:\\Users\\leohe\\Documents\\ITC\\HIVE\\Challenge\\asl_alphabet_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked, label = load_folders(FILEDIR, n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = np.load('ASL_x_gray.npy')\n",
    "label   = np.load('ASL_y_gray.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86130 870\n"
     ]
    }
   ],
   "source": [
    "idx = shuffle(np.arange(len(label)))\n",
    "# stacked, label = shuffle(stacked, label)\n",
    "idx_train, idx_test = train_test_split(idx, test_size=0.01)\n",
    "print(len(idx_train), len(idx_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 200, 200)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 196, 64)           64064     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 196, 64)           256       \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 192, 32)           10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 192, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 96, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 92, 16)            2576      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 92, 16)            64        \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 88, 8)             648       \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 88, 8)             32        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 44, 8)             0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 352)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 400)               141200    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 200)               80200     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 29)                1479      \n",
      "=================================================================\n",
      "Total params: 336,169\n",
      "Trainable params: 335,929\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape=stacked[idx_train].shape[1:])\n",
    "f = layers.Conv1D(64, (5))(inputs)\n",
    "f = layers.BatchNormalization()(f)\n",
    "f = layers.Conv1D(32, (5), activation='relu')(f)\n",
    "f = layers.BatchNormalization()(f)\n",
    "f = layers.MaxPool1D()(f)\n",
    "f = layers.Conv1D(16, (5), activation='relu')(f)\n",
    "f = layers.BatchNormalization()(f)\n",
    "f = layers.Conv1D( 8, (5), activation='relu')(f)\n",
    "f = layers.BatchNormalization()(f)\n",
    "f = layers.MaxPool1D()(f)\n",
    "f = layers.Flatten()(f)\n",
    "f = layers.Dense(400, activation='relu')(f)\n",
    "f = layers.Dense(200, activation='relu')(f)\n",
    "f = layers.Dense(100, activation='relu')(f)\n",
    "f = layers.Dense(100, activation='relu')(f)\n",
    "f = layers.Dense( 50, activation='relu')(f)\n",
    "outputs = layers.Dense(len(np.unique(label[idx_train])), activation='softmax')(f)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x=stacked[idx_train] / np.max(stacked[idx_train]), \n",
    "                    y=to_categorical(label[idx_train], len(np.unique(label[idx_train]))), \n",
    "                    batch_size=128, epochs=20,) \n",
    "#                     validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['acc'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "# summarize history for loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(x=stacked[idx_test] / np.max(stacked[idx_test]), y=to_categorical(label[idx_test], len(np.unique(label[idx_test]))))\n",
    "print(\"Test Set\\tLoss : {:2f}\\t\\tAccuracy : {:6.2f}%\".format(loss, 100 * acc))\n",
    "targets = np.argmax(to_categorical(label[idx_test], len(np.unique(label[idx_test]))), axis=-1)\n",
    "probabilities = model.predict(x=stacked[idx_test] / np.max(stacked[idx_test]))\n",
    "predictions = np.argmax(probabilities, axis=-1)\n",
    "cm = confusion_matrix(y_true=targets, y_pred=predictions)\n",
    "# print(cm)\n",
    "plot_confusion_matrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "for letter in LABEL:\n",
    "    for entry, pred, sample in zip(label[idx_test], predictions, stacked[idx_test]):\n",
    "        if entry[0] != pred and entry[0] == LABEL[letter]:\n",
    "            plt.figure()\n",
    "            plt.imshow(sample, cmap='gray')\n",
    "            plt.title(\"True {}, Pred {}\".format(list(LABEL.keys())[entry[0]], list(LABEL.keys())[pred]))\n",
    "            plt.show()\n",
    "#             print(entry[0], pred)\n",
    "            break\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filedir = r'C:/Users/leohe/Documents/ITC/HIVE/Challenge/our_asl_test_set/'\n",
    "folder_list = [folder for folder in os.listdir(filedir)]\n",
    "test_stacked  = np.empty((17, 200, 200), dtype='uint8')\n",
    "test_label = np.empty((17, 1), dtype='uint8')\n",
    "count = 0\n",
    "for folder in folder_list:\n",
    "    subfolder = filedir + '\\\\' + folder\n",
    "    file_list = [file for file in os.listdir(subfolder)]\n",
    "    for file in file_list:\n",
    "        img = cv2.imread(subfolder + '\\\\' + file, 0)\n",
    "        img = resampling(img, 3)\n",
    "        img = cv2.resize(img, (200, 200))\n",
    "        test_stacked[count] = img.astype('int8')\n",
    "        test_label[count] = LABEL[folder]\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(x=test_stacked / np.max(test_stacked), y=to_categorical(test_label, 29))\n",
    "print(\"Test Set\\tLoss : {:2f}\\t\\tAccuracy : {:6.2f}%\".format(loss, 100 * acc))\n",
    "targets = np.argmax(to_categorical(test_label, 29), axis=-1)\n",
    "probabilities = model.predict(x=test_stacked / np.max(test_stacked))\n",
    "predictions = np.argmax(probabilities, axis=-1)\n",
    "cm = confusion_matrix(y_true=targets, y_pred=predictions)\n",
    "# print(cm)\n",
    "plot_confusion_matrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for pred, sample, prob in zip(predictions, test_stacked, probabilities):\n",
    "    if pred != 0:\n",
    "        for index, p in enumerate(prob):\n",
    "            print(\"{} : {:6.2f}%\".format(index, 100 * p))\n",
    "        plt.figure()\n",
    "        plt.imshow(sample, cmap='gray')\n",
    "        plt.title(\"{}\".format(list(LABEL.keys())[pred]))\n",
    "        plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
